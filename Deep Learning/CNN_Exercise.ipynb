{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TAbdullah-T/T5-SAD/blob/main/Deep%20Learning/CNN_Exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6edf0915",
      "metadata": {
        "id": "6edf0915"
      },
      "source": [
        "# Convolutional Neural Network (CNN) using Keras\n",
        "This notebook will guide you through the process of creating a CNN model using Keras. Follow the steps and fill in the code blocks as you progress."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf19bf02",
      "metadata": {
        "id": "cf19bf02"
      },
      "source": [
        "# Dataset Card: Men vs. Women Classification\n",
        "\n",
        "## Overview\n",
        "The Men vs. Women Classification dataset contains images of men and women intended for binary image classification tasks. The goal is to classify images based on gender.\n",
        "\n",
        "- **Dataset URL:** [Men vs. Women Classification Dataset](https://www.kaggle.com/datasets/saadpd/menwomen-classification)\n",
        "- **Dataset Size:** ~845 MB\n",
        "- **Classes:** 2 (Men, Women)\n",
        "- **Image Format:** JPEG\n",
        "\n",
        "## Structure\n",
        "\n",
        "### Folders\n",
        "The dataset is organized into two main folders:\n",
        "\n",
        "- `traindata/`:\n",
        "  - `traindata/`: Contains the training images.\n",
        "    - `men/`: Contains images of men.\n",
        "    - `women/`: Contains images of women.\n",
        "\n",
        "- `testdata/`:\n",
        "  - `testdata/`: Contains the testing images.\n",
        "    - `men/`: Contains images of men.\n",
        "    - `women/`: Contains images of women.\n",
        "\n",
        "### Example Files\n",
        "Here are some example file names you might find in the dataset:\n",
        "\n",
        "- `traindata/traindata/men/000000899.jpg`\n",
        "- `traindata/traindata/women/00000001.jpg`\n",
        "- `testdata/testdata/men/00000504.jpg`\n",
        "- `testdata/testdata/women/00000002.jpg`\n",
        "\n",
        "### Image Specifications\n",
        "- **Resolution:** Varies\n",
        "- **Color:** RGB\n",
        "\n",
        "## Usage\n",
        "This dataset is ideal for practicing binary image classification using Convolutional Neural Networks (CNNs). It can be used to train a model to distinguish between images of men and women."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c25150e3",
      "metadata": {
        "id": "c25150e3"
      },
      "source": [
        "## Step 1: Import Required Libraries\n",
        "Begin by importing the necessary libraries."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSSeGxQyYQ4A",
        "outputId": "37617df1-4137-48fc-c13b-fd597ba064dc"
      },
      "id": "VSSeGxQyYQ4A",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.5)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d saadpd/menwomen-classification"
      ],
      "metadata": {
        "id": "8WbZfVOi8QBY",
        "outputId": "fe696d2d-b997-4b81-c12c-dd4072dd4cea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "8WbZfVOi8QBY",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/saadpd/menwomen-classification\n",
            "License(s): copyright-authors\n",
            "menwomen-classification.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aaa74530",
      "metadata": {
        "id": "aaa74530",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbcd0cee-dd1c-4ba3-cb28-1342b66c0b19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/menwomen-classification.zip\n",
            "replace /content/testdata/testdata/men/00000001.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!unzip /content/menwomen-classification.zip -d /content\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.regularizers import l1_l2\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, BatchNormalization, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Pc6fHTElbYHE"
      },
      "id": "Pc6fHTElbYHE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "9df0ba8e",
      "metadata": {
        "id": "9df0ba8e"
      },
      "source": [
        "## Step 2: Load and Preprocess Data\n",
        "Load your dataset and preprocess it. This may include resizing images, normalizing pixel values, and splitting the data into training and validation sets."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_resize_image(img_Path):\n",
        "  image = Image.open(img_Path).convert('RGB')\n",
        "  image = image.resize((100,100))\n",
        "  return np.array(image)\n",
        "\n",
        "\n",
        "def load_images_with_labels(folder_path):\n",
        "\n",
        "  labels = ['men', 'women']\n",
        "  img = []\n",
        "  labels_ = []\n",
        "  for label in labels :\n",
        "    folder_path_label = os.path.join(folder_path, label)\n",
        "    for filename in os.listdir(folder_path_label):\n",
        "      img_path = os.path.join(folder_path_label, filename)\n",
        "      img.append(load_and_resize_image(img_path))\n",
        "      labels_.append(label)\n",
        "\n",
        "  img = np.array(img)\n",
        "  labels_ = np.array(labels_)\n",
        "  return img, labels_\n",
        "\n",
        "X, y = load_images_with_labels('/content/Dataset/testdata')"
      ],
      "metadata": {
        "id": "-sUQBHlknky9"
      },
      "id": "-sUQBHlknky9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optionally, you can convert the labels to numerical values if needed\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)"
      ],
      "metadata": {
        "id": "rbmwUQoGtBB_"
      },
      "id": "rbmwUQoGtBB_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X,y_encoded, test_size=0.2, shuffle= True, random_state=0)"
      ],
      "metadata": {
        "id": "ueOucOH3q9bZ"
      },
      "id": "ueOucOH3q9bZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape , y_train.shape, X_val.shape"
      ],
      "metadata": {
        "id": "CN8izngvxWNy",
        "outputId": "2b483c5e-4d88-42e2-b190-9537e2fb34d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "CN8izngvxWNy",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1066, 100, 100, 3), (1066,), (267, 100, 100, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print((y_train))"
      ],
      "metadata": {
        "id": "0PHsY5JHxpRn",
        "outputId": "7d250a5a-4ea3-4aa3-f706-ed30c53a8b52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "0PHsY5JHxpRn",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 0 ... 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2932d543",
      "metadata": {
        "id": "2932d543"
      },
      "source": [
        "## Step 3: Data Augmentation\n",
        "To prevent overfitting, augment your data using various transformations like rotation, zoom, flip, etc."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    rescale = 1/255,\n",
        "    rotation_range = 15,\n",
        "    width_shift_range = 0.2,\n",
        "    height_shift_range = 0.2,\n",
        "    horizontal_flip = True,\n",
        "    zoom_range = 0.2,\n",
        ")\n",
        "datagen.fit(X_train)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "fmhcZwjWeTM1"
      },
      "id": "fmhcZwjWeTM1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "d77d214a",
      "metadata": {
        "id": "d77d214a"
      },
      "source": [
        "## Step 4: Build the CNN Model\n",
        "Define the architecture of your CNN model. Start with convolutional layers followed by pooling layers, and end with fully connected layers."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = Sequential([\n",
        "\n",
        "        Conv2D(32, (3,3), activation='relu', padding = 'same', input_shape=(100,100,3),\n",
        "              kernel_regularizer=l1_l2(l1=0.01, l2=0.01),),\n",
        "\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.5),\n",
        "        Conv2D(32, (3,3), activation='relu', padding='same',kernel_regularizer=l1_l2(l1=0.01, l2=0.01)),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.5),\n",
        "        MaxPooling2D(2,2),\n",
        "\n",
        "        Conv2D(64, (3,3), activation='relu', padding='same',kernel_regularizer=l1_l2(l1=0.01, l2=0.01)),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.5),\n",
        "        Conv2D(64, (3,3),activation='relu', padding='same',kernel_regularizer=l1_l2(l1=0.01, l2=0.01)),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.5),\n",
        "        MaxPooling2D(2,2),\n",
        "\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu',kernel_regularizer=l1_l2(l1=0.01, l2=0.01)),\n",
        "        BatchNormalization(),\n",
        "        Dense(1, activation='sigmoid')\n",
        "])\n"
      ],
      "metadata": {
        "id": "wZSNDReDt9o4",
        "outputId": "130f0642-7fd3-4a66-ee56-69e4b914d19f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "wZSNDReDt9o4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "066c1d25",
      "metadata": {
        "id": "066c1d25"
      },
      "source": [
        "## Step 5: Compile the Model\n",
        "Compile your model by specifying the optimizer, loss function, and evaluation metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83b3fe4b",
      "metadata": {
        "id": "83b3fe4b"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eec6e31d",
      "metadata": {
        "id": "eec6e31d"
      },
      "source": [
        "## Step 6: Train the Model\n",
        "Train your model using the training data and validate it using the validation data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd761a43",
      "metadata": {
        "id": "cd761a43"
      },
      "outputs": [],
      "source": [
        "history = model.fit(datagen.flow(X_train,y_train, batch_size=64),\n",
        "                    batch_size= 1000,\n",
        "                    epochs = 10,\n",
        "                    validation_data = (X_val,y_val),\n",
        "                    verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37e265a8",
      "metadata": {
        "id": "37e265a8"
      },
      "source": [
        "## Step 7: Evaluate the Model\n",
        "Evaluate the performance of your model using the validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08f53419",
      "metadata": {
        "id": "08f53419"
      },
      "outputs": [],
      "source": [
        "def load_resize_image(file_path):\n",
        "  image = Image.open(file_path).convert('RGB')\n",
        "  image = image.resize((100,100))\n",
        "  return np.array(image )\n",
        "\n",
        "def load_img_label(folder_path):\n",
        "  labels = ['men','women']\n",
        "  img = []\n",
        "  labels_ = []\n",
        "  for label in labels :\n",
        "    label_path = os.path.join(folder_path, label)\n",
        "    for filename in os.listdir(label_path) :\n",
        "      img_path = os.path.join(label_path, filename)\n",
        "      img.append(load_resize_image(img_path))\n",
        "      labels_.append(label)\n",
        "\n",
        "  return np.array(img) , np.array(labels_)\n",
        "\n",
        "X_test, y_test = load_img_label('/content/Dataset/testdata')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_enc = label_encoder.transform(y_test)"
      ],
      "metadata": {
        "id": "86S7zqht0I7D"
      },
      "id": "86S7zqht0I7D",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test,y_enc)"
      ],
      "metadata": {
        "id": "Vk7ADBzQ1kWN",
        "outputId": "2aedc472-f391-46d9-a95b-2b138924bf51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Vk7ADBzQ1kWN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 493ms/step - accuracy: 0.6583 - loss: 41.3305\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[79.00054168701172, 0.3150787651538849]"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb612a4c",
      "metadata": {
        "id": "eb612a4c"
      },
      "source": [
        "## Step 8: Save the Model\n",
        "Finally, save your trained model for future use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9688067c",
      "metadata": {
        "id": "9688067c"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}